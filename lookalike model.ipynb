{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f82f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install surprise\n",
    "#!pip install xgboost\n",
    "#!pip install --upgrade numpy scikit-learn\n",
    "#!conda update --all\n",
    "#!export OPENBLAS_NUM_THREADS=1\n",
    "#!pip install node2vec\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca8b9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookalike user indices: [2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_lookalike(seed_users, candidate_users, top_n=100):\n",
    "    similarities = cosine_similarity(seed_users, candidate_users)\n",
    "    avg_similarities = np.mean(similarities, axis=0)\n",
    "    top_indices = np.argsort(avg_similarities)[-top_n:]\n",
    "    return top_indices[::-1]\n",
    "\n",
    "# Example usage\n",
    "seed_users = np.array([[1, 0, 1, 1], [1, 1, 0, 1]])\n",
    "candidate_users = np.array([[1, 0, 1, 0], [0, 1, 1, 1], [1, 1, 1, 0]])\n",
    "lookalike_indices = cosine_similarity_lookalike(seed_users, candidate_users, top_n=1)\n",
    "print(\"Lookalike user indices:\", lookalike_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb558972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (15000, 3)\n",
      "Sample of the dataset:\n",
      "   user_id  item_id  rating\n",
      "0      103        3       2\n",
      "1      436       67       3\n",
      "2      861       71       5\n",
      "3      271      100       3\n",
      "4      107       35       1\n",
      "\n",
      "Seed users: [961, 583, 15, 650, 432]\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Number of lookalike users found: 57\n",
      "Sample of lookalike users: [770, 386, 131, 898, 647, 777, 14, 271, 274, 277]\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def generate_sample_data(n_users=1000, n_items=100, n_ratings=10000):\n",
    "    np.random.seed(42)\n",
    "    user_ids = np.random.randint(1, n_users + 1, n_ratings)\n",
    "    item_ids = np.random.randint(1, n_items + 1, n_ratings)\n",
    "    ratings = np.random.randint(1, 6, n_ratings)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'user_id': user_ids,\n",
    "        'item_id': item_ids,\n",
    "        'rating': ratings\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def collaborative_filtering_lookalike(ratings, seed_users, n_neighbors=20, top_n=100):\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(ratings[['user_id', 'item_id', 'rating']], reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    \n",
    "    sim_options = {'name': 'cosine', 'user_based': True}\n",
    "    model = KNNBasic(k=n_neighbors, sim_options=sim_options)\n",
    "    model.fit(trainset)\n",
    "    \n",
    "    lookalike_users = []\n",
    "    for seed_user in seed_users:\n",
    "        try:\n",
    "            neighbors = model.get_neighbors(trainset.to_inner_uid(seed_user), k=top_n)\n",
    "            lookalike_users.extend([trainset.to_raw_uid(neighbor) for neighbor in neighbors])\n",
    "        except ValueError:\n",
    "            print(f\"Seed user {seed_user} not found in the dataset.\")\n",
    "    \n",
    "    return list(set(lookalike_users))\n",
    "\n",
    "# Generate sample dataset\n",
    "ratings = generate_sample_data(n_users=1000, n_items=100, n_ratings=15000)\n",
    "print(\"Dataset shape:\", ratings.shape)\n",
    "print(\"Sample of the dataset:\")\n",
    "print(ratings.head())\n",
    "\n",
    "# Select seed users (randomly choosing 5 users from the dataset)\n",
    "seed_users = ratings['user_id'].sample(5).tolist()\n",
    "print(\"\\nSeed users:\", seed_users)\n",
    "\n",
    "# Find lookalike users\n",
    "lookalike_users = collaborative_filtering_lookalike(ratings, seed_users, n_neighbors=10, top_n=20)\n",
    "print(\"\\nNumber of lookalike users found:\", len(lookalike_users))\n",
    "print(\"Sample of lookalike users:\", lookalike_users[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f6a1e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results:\n",
      "AUC: 0.5189\n",
      "Accuracy: 0.8950\n",
      "Number of lookalike users found: 0\n",
      "Sample lookalike user indices: []\n",
      "\n",
      "Random Forest Results:\n",
      "AUC: 0.5148\n",
      "Accuracy: 0.8950\n",
      "Number of lookalike users found: 0\n",
      "Sample lookalike user indices: []\n",
      "\n",
      "XGBoost Results:\n",
      "AUC: 0.4660\n",
      "Accuracy: 0.8935\n",
      "Number of lookalike users found: 3\n",
      "Sample lookalike user indices: [ 39 306 500]\n",
      "\n",
      "Random Forest Feature Importance:\n",
      "Feature_5    0.103437\n",
      "Feature_7    0.101610\n",
      "Feature_2    0.101282\n",
      "Feature_9    0.100863\n",
      "Feature_6    0.100784\n",
      "Feature_3    0.099907\n",
      "Feature_8    0.099767\n",
      "Feature_0    0.098878\n",
      "Feature_4    0.097367\n",
      "Feature_1    0.096107\n",
      "dtype: float64\n",
      "\n",
      "XGBoost Feature Importance:\n",
      "Feature_5    0.106682\n",
      "Feature_4    0.102541\n",
      "Feature_3    0.101570\n",
      "Feature_8    0.100941\n",
      "Feature_9    0.100126\n",
      "Feature_2    0.099114\n",
      "Feature_1    0.098084\n",
      "Feature_6    0.097890\n",
      "Feature_7    0.097101\n",
      "Feature_0    0.095953\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Generate a larger sample dataset\n",
    "def generate_sample_data(n_samples=10000, n_features=10, seed_ratio=0.1):\n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    y = np.random.choice([0, 1], size=n_samples, p=[1-seed_ratio, seed_ratio])\n",
    "    return X, y\n",
    "\n",
    "# Lookalike modeling using Logistic Regression\n",
    "def logistic_regression_lookalike(X, y, candidate_users, threshold=0.5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_test, y_pred_proba >= threshold)\n",
    "    \n",
    "    candidate_users_scaled = scaler.transform(candidate_users)\n",
    "    candidate_proba = model.predict_proba(candidate_users_scaled)[:, 1]\n",
    "    lookalike_indices = np.where(candidate_proba >= threshold)[0]\n",
    "    \n",
    "    return lookalike_indices, auc, accuracy\n",
    "\n",
    "# Lookalike modeling using Random Forest\n",
    "def random_forest_lookalike(X, y, candidate_users, threshold=0.5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_test, y_pred_proba >= threshold)\n",
    "    \n",
    "    candidate_proba = model.predict_proba(candidate_users)[:, 1]\n",
    "    lookalike_indices = np.where(candidate_proba >= threshold)[0]\n",
    "    \n",
    "    return lookalike_indices, auc, accuracy\n",
    "\n",
    "# Lookalike modeling using XGBoost\n",
    "def xgboost_lookalike(X, y, candidate_users, threshold=0.5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_test, y_pred_proba >= threshold)\n",
    "    \n",
    "    candidate_proba = model.predict_proba(candidate_users)[:, 1]\n",
    "    lookalike_indices = np.where(candidate_proba >= threshold)[0]\n",
    "    \n",
    "    return lookalike_indices, auc, accuracy\n",
    "\n",
    "# Generate sample data\n",
    "X, y = generate_sample_data(n_samples=10000, n_features=10, seed_ratio=0.1)\n",
    "candidate_users = np.random.randn(1000, 10)  # 1000 candidate users\n",
    "\n",
    "# Run all three models\n",
    "models = [\n",
    "    (\"Logistic Regression\", logistic_regression_lookalike),\n",
    "    (\"Random Forest\", random_forest_lookalike),\n",
    "    (\"XGBoost\", xgboost_lookalike)\n",
    "]\n",
    "\n",
    "for model_name, model_func in models:\n",
    "    lookalike_indices, auc, accuracy = model_func(X, y, candidate_users)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Number of lookalike users found: {len(lookalike_indices)}\")\n",
    "    print(f\"Sample lookalike user indices: {lookalike_indices[:10]}\")\n",
    "\n",
    "# Compare feature importance (for Random Forest and XGBoost)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "feature_importance_rf = pd.Series(rf_model.feature_importances_, index=[f\"Feature_{i}\" for i in range(X.shape[1])])\n",
    "feature_importance_xgb = pd.Series(xgb_model.feature_importances_, index=[f\"Feature_{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "print(\"\\nRandom Forest Feature Importance:\")\n",
    "print(feature_importance_rf.sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nXGBoost Feature Importance:\")\n",
    "print(feature_importance_xgb.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec42bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookalike user indices: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def kmeans_lookalike(seed_users, candidate_users, n_clusters=5, top_n=100):\n",
    "    all_users = np.vstack([seed_users, candidate_users])\n",
    "    scaler = StandardScaler()\n",
    "    all_users_scaled = scaler.fit_transform(all_users)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(all_users_scaled)\n",
    "    \n",
    "    seed_clusters = cluster_labels[:len(seed_users)]\n",
    "    candidate_clusters = cluster_labels[len(seed_users):]\n",
    "    \n",
    "    lookalike_indices = []\n",
    "    for cluster in np.unique(seed_clusters):\n",
    "        cluster_candidates = np.where(candidate_clusters == cluster)[0]\n",
    "        lookalike_indices.extend(cluster_candidates[:top_n])\n",
    "    \n",
    "    return lookalike_indices\n",
    "\n",
    "# Example usage\n",
    "seed_users = np.array([[1, 0, 1], [1, 1, 1]])\n",
    "candidate_users = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 0], [0, 0, 1]])\n",
    "lookalike_indices = kmeans_lookalike(seed_users, candidate_users, n_clusters=2, top_n=1)\n",
    "print(\"Lookalike user indices:\", lookalike_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d665cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Computing transition probabilities: 100%|████| 100/100 [00:00<00:00, 389.67it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [00:00<00:00, 106.10it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 50/50 [00:00<00:00, 106.04it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 50/50 [00:00<00:00, 106.79it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:00<00:00, 106.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookalike nodes: [18, 88, 21, 4, 36, 46, 45]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def graph_based_lookalike(graph, seed_nodes, dimensions=64, walk_length=30, num_walks=200, top_n=100):\n",
    "    node2vec = Node2Vec(graph, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, workers=4)\n",
    "    model = node2vec.fit(window=10, min_count=1)\n",
    "    \n",
    "    all_embeddings = np.array([model.wv[node] for node in graph.nodes()])\n",
    "    seed_embeddings = np.array([model.wv[node] for node in seed_nodes])\n",
    "    \n",
    "    similarities = cosine_similarity(seed_embeddings, all_embeddings)\n",
    "    avg_similarities = np.mean(similarities, axis=0)\n",
    "    \n",
    "    top_indices = np.argsort(avg_similarities)[-top_n:]\n",
    "    return [list(graph.nodes())[i] for i in top_indices[::-1] if list(graph.nodes())[i] not in seed_nodes]\n",
    "\n",
    "# Example usage\n",
    "G = nx.fast_gnp_random_graph(100, 0.5)\n",
    "seed_nodes = [0, 1, 2]\n",
    "lookalike_nodes = graph_based_lookalike(G, seed_nodes, top_n=10)\n",
    "print(\"Lookalike nodes:\", lookalike_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601e2327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Lookalike user indices: [2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def deep_learning_lookalike(X, y, candidate_users, threshold=0.7):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    candidate_proba = model.predict(candidate_users)\n",
    "    lookalike_indices = np.where(candidate_proba >= threshold)[0]\n",
    "    return lookalike_indices\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[1, 0, 1], [1, 1, 1], [0, 1, 0], [0, 0, 1]])\n",
    "y = np.array([1, 1, 0, 0])  # 1 for seed users, 0 for non-seed users\n",
    "candidate_users = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 0]])\n",
    "lookalike_indices = deep_learning_lookalike(X, y, candidate_users)\n",
    "print(\"Lookalike user indices:\", lookalike_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29cb21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573aaebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
